# Optimization Using Gradient Descent: Linear Regression

## Overview
This project explores linear regression implementation using multiple approaches:
- Linear regression using NumPy's polyfit
- Machine learning models from scikit-learn
- Gradient descent implementation from scratch

## Key Components

### Data Analysis
- Analysis of TV marketing expenses vs. sales data
- Data preprocessing including normalization
- Train-test splitting for model evaluation

### Implementation Methods
1. **NumPy Implementation**: Using `polyfit` to calculate the regression coefficients
2. **Scikit-learn Implementation**: Using `LinearRegression` estimator
3. **Gradient Descent Implementation**: Building linear regression from scratch
4. **Advanced Models**: Comparison with Random Forest and Decision Tree regressors

### Performance Evaluation
- Calculation of Root Mean Squared Error (RMSE) for model comparison
- Model ranking based on performance metrics
- Prediction visualization

## Requirements
- Python 3.x
- NumPy
- pandas
- scikit-learn
- Matplotlib (for visualizations)

## Key Learnings
- Implementation of linear regression using different approaches
- Understanding of gradient descent optimization
- Model comparison techniques
- Practical experience with normalization and denormalization

This project demonstrates both theoretical understanding and practical implementation of linear regression, emphasizing the optimization process through gradient descent.
